{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA av qualis",
      "provenance": [],
      "collapsed_sections": [
        "skOlMxFSgpEH"
      ],
      "authorship_tag": "ABX9TyMRMOheN/9lEO3W3iy1qZ2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucas-Melo-A-S/Data_Science/blob/main/IA_av_qualis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AVqualis - Inteligencia Artificial"
      ],
      "metadata": {
        "id": "2PWZUOCP6O00"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O presente trabalho tem como objetivo identificar qual tipo de fruta é atravês das imagens importadas no sistema. Esse é um projeto comum na comunidade de tecnologia.\n",
        "O projeto a seguir foi baseado no projeto realizado pelo Cientista de Dados Gabriel Atkin."
      ],
      "metadata": {
        "id": "qRJvt4et6Osk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para inicio do projeto iremos importar as bibliotecas que serão utilizadas aos longo do nosso projeto. Vale informar que também podemos importar as bibliotecas/ metodos ao longo de todo o corpo do projeto mas para melhor organização iremos deixar estas no inicio."
      ],
      "metadata": {
        "id": "BZxSMX8E70GF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct3t3xT_2Xo_",
        "outputId": "15a37788-7f97-4df1-b2ae-409cd9d0e646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "#Importando as Bibliotecas:\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Criando a lista com o filepath para treinamento e teste -  Iremos utilizar o metodo Path para que não tenhamos erros se caso tenha mudança de SO. Como o Windows tem caminhos(path) diferente do OS(MAC),Linux podemos utilizar o Path como um opção, pois esse método irá escrever o arquivo de acordo com o SO utilizado.\n",
        "\n",
        "- Com o  metodo GLOB iremos falar para o sistema pesquisar ao longo de todo o arquivo procurando arquivo que ser sufixoé .jpg. Com isso iremos selecionar apenas imagens.\n"
      ],
      "metadata": {
        "id": "9QkatPyg_q8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "image_dir = Path(\"C:\\\\Users\\\\User\\\\Downloads\\\\archive\\\\images\")\n",
        "\n",
        "filepaths = list(image_dir.glob(r'**/*.jpg'))\n"
      ],
      "metadata": {
        "id": "RkyUaOmnLtxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(image_dir.glob('**/*.jpg'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee7QaX2WhNr3",
        "outputId": "12dc3510-4e6c-4611-f2bf-c95a4e758f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Para a criação do DataFrame concatenar nosso filepath com a sua classe.\n",
        " - Para encontrar marcar a classe iremos procurar no proprio diretorio do arquivo. Para isso iremos utilizar o metodo SPLIT() para realizarmos o corte do arquivo até deixarmos apenas a classe de cada arquivo. Para automatizar esse processo iremos fazer um for em todo o diretorio dos arquivos(filepath)\n",
        "\n",
        "- Encontrado a classe, iremos trnasformar o datapath e os labels em pandas dataframe e depois iremos concatenar tudo em dentro um novo dataframe chamado df.\n",
        " - Para que as classes não fiquem sempre uma seguida da outra, fazemos uma mistura(shuffle) e resetando também seu index para que o index fique de acordo com o novo dataframe criado"
      ],
      "metadata": {
        "id": "L59jcvyPERDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # Create a DataFrame with the filepath and the labels of the pictures\n",
        "\n",
        "    # You you probably need to adapt this split method to your Pc path, mine was using this double bars\n",
        "# labels = [str(filepaths[i]).split(\"\\\\\")[-2] \\\n",
        "#             for i in range(len(filepaths))]\n",
        "    \n",
        "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
        "\n",
        "filepath = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "    # Concatenate filepaths and labels\n",
        "images = pd.concat([filepath, labels], axis=1)\n"
      ],
      "metadata": {
        "id": "vqg_GFSQ5wfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e352ef5b-6b5f-49ef-9ed9-4273baa58564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "z9cDj0z2hIWu",
        "outputId": "870d72a8-7e97-480a-dd96-df0ab587e6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Filepath, Label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9173a6e1-f193-4e1f-bb19-46307f8eab45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filepath</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9173a6e1-f193-4e1f-bb19-46307f8eab45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9173a6e1-f193-4e1f-bb19-46307f8eab45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9173a6e1-f193-4e1f-bb19-46307f8eab45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos ver nessa situação teremos 101000 imagens e com isso seria muito demorado fazer a classificação de todas as imagens. Com isso iremos reduzir a quantidade de imagens para que nosso processo seja mais rápido.\n"
      ],
      "metadata": {
        "id": "1e3_xlJ9NvQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_samples = []\n",
        "for category in images['Label'].unique():\n",
        "    category_slice = images.query(\"Label == @category\")\n",
        "    category_samples.append(category_slice.sample(100, random_state=1))\n",
        "image_df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "sTF_NZu8Nu8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "4d1424ce-ef55-43ee-e41e-a72844ba4645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1c74997e8ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcategory_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label == @category\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcategory_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após essa separação o nosso dataframe terá 10100 imagens, sendo assim o processo ficará mais rápido."
      ],
      "metadata": {
        "id": "vAIPqjT_Pomr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_df"
      ],
      "metadata": {
        "id": "oidyHMTbP7TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_df['Labels'].value_counts()"
      ],
      "metadata": {
        "id": "PJuYAzU_P-yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Treinando e Testando "
      ],
      "metadata": {
        "id": "hOuRNdkyQLvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após todo o processo de modelagem e limpeza do dataframe, iremos fazer o teste e treino.\n",
        "- Utilizaremos o metodo train_test_split, onde nesse iremos dividir o dataframe em dois, o de teste e o de treino, nesse método temos que falar o dataframe que será recortado, o tamanho do train/test.(Nessa situação também falamos para misturar pois não queremos que o teste ou o treino contenham somente um tipo de classe, também é utilizado o randon_state para que sempre que realizarmos esse ação, os dados divididos sejam os mesmos.)"
      ],
      "metadata": {
        "id": "wccXb5PEQmph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separando em dataframe de teste e treino\n",
        "train_df,test_df = train_test_split(image_df,train_size = 0.7, \n",
        "                                    shuffle = True, \n",
        "                                    random_state = 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "iMUhOtCCQQw7",
        "outputId": "b9110d1f-b55a-47cd-eeba-11c215f41b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-19b72663348c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Separando em dataframe de teste e treino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_df,test_df = train_test_split(image_df,train_size = 0.7, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     random_state = 2)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Geradores\n",
        "\n",
        "- Iremos utilar a biblioteca TensorFlow para carregar as imagens uma de cada vez para não sobrecarregar a memoria. Com os geradores iremos especificar como que os dados irão carregar durante o treinamento."
      ],
      "metadata": {
        "id": "jFUuc1VWSd5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        ")"
      ],
      "metadata": {
        "id": "W4GyWDkRUGLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Especificando os geradores de como queremos carregar os dados durante o treino.\n",
        "- Nessa situação iremos utilizar o método 'flow_from_dataframe' onde iremos especificar a imagem  que estamos usando para que o gerador pegue essas imagens do dataframe para treina-las e assim recicla-las.\n",
        "- Nesse metodo teremos que especificar o dataframe, a coluna em X e Y, dando o tamanho da imagem, cor, o modo da classe entre outras funções.Esse metodo vai ser utilizado tanto para o dataframe de treino(train), quanto para o de teste(test). No caso da validação, iremos criar uma variavel, onde esta variavel irá receber o train_generator.(Preste atenção no subset, ele modificação).\n"
      ],
      "metadata": {
        "id": "fFOOHpXxU4w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe = train_df,\n",
        "    x_col = 'Filepath',\n",
        "    y_col = 'Label',\n",
        "    target.size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    classe_mode = 'categorical',\n",
        "    batch_size = 32,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    subset = 'training' #Utilizado quando temos a validação no gerador.\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "val_images= train_generator.flow_from_dataframe(\n",
        "    dataframe = train_df,\n",
        "    x_col = 'Filepath',\n",
        "    y_col = 'Label',\n",
        "    target.size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    classe_mode = 'categorical',\n",
        "    batch_size = 32,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    subset = 'validation'\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe = test_df,\n",
        "    x_col = 'Filepath',\n",
        "    y_col = 'Label',\n",
        "    target.size = (224,224),\n",
        "    color_mode = 'rgb',\n",
        "    classe_mode = 'categorical',\n",
        "    batch_size = 32,\n",
        "    shuffle = False,\n",
        "    seed = 42,\n",
        ")"
      ],
      "metadata": {
        "id": "vNnfvIkTVppA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelagem"
      ],
      "metadata": {
        "id": "y6wM1MPHX2hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a modelagem iremos utilizar o MobileNetV2, esse método retorna um modelo de classificação de Imagem Keras."
      ],
      "metadata": {
        "id": "Dd_8goMSFs7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape = (224,224,3),\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    pooling = 'avg'\n",
        ")\n",
        "\n",
        "pretrained_model.trainable = False #Esse comodo faz termos certeza que não iremos modificar o peso das imagens no dataframe original."
      ],
      "metadata": {
        "id": "JroQEIYzX4hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model take some minutes, so if you don't want to run this cell its ok, the trained model for vegetables and fruits is already saved in the project root(FV.h5)\n",
        "inputs = pretrained_model.input\n",
        "\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(101, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "cwNRjULM5wFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treino"
      ],
      "metadata": {
        "id": "yh72PvQaguNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para o treinamento iremos primeiro compilar o input com output e após isso iremos fazer o treinamento do modelo com o método .fit."
      ],
      "metadata": {
        "id": "Bm87zedACFKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    batch_size = 32,\n",
        "    epochs=100,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=2,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "ZJVX6S8VHlEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resultados"
      ],
      "metadata": {
        "id": "jEy6CCJoIcgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_images, verbose = 0)\n",
        "print(\"Test Accuracy:{:.2f}\".format(results[1] * 100))"
      ],
      "metadata": {
        "id": "uFkeS2z8Iqs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label of the test_images\n",
        "pred = np.argmax(model.predict(test_images), axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "# Map the label\n",
        "labels = (train_images.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "pred1 = [labels[k] for k in pred]\n",
        "pred1"
      ],
      "metadata": {
        "id": "YFPvEh7L5v6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix\n",
        "cm = confusion_matrix(test_images.labels,pred)\n",
        "clr = classification_report(test_images.labels, predictions, target_names = test.images.class_indices)\n",
        "\n",
        "plt.figura(figsize = (30, 30))\n",
        "sns.heatmap(cm, annot = True, fmt = 'g', cmap = 'Blues', cbar = False)\n",
        "\n",
        "plt.xtick(ticks = np.arange(101) + 0.5, labels = test_images.class_indices,rotatio = 90)\n",
        "plt.ytick(ticks = np.arange(101) + 0.5, labels = test_images.class_indices,rotatio = 0)\n",
        "plt.xlabel('pREDICTED')\n",
        "plt.title('Confusion Matrix')"
      ],
      "metadata": {
        "id": "nouvXIcqJbdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\\n-------------\\n\", clr)"
      ],
      "metadata": {
        "id": "wtkH_IwzK4fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.class_indices"
      ],
      "metadata": {
        "id": "vkvHGLXCKO5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output(location):\n",
        "    img=load_img(location,target_size=(224,224,3))\n",
        "    img=img_to_array(img)\n",
        "    img=img/255\n",
        "    img=np.expand_dims(img,[0])\n",
        "    answer=model.predict(img)\n",
        "    y_class = answer.argmax(axis=-1)\n",
        "    y = \" \".join(str(x) for x in y_class)\n",
        "    y = int(y)\n",
        "    res = labels[y]\n",
        "    return res"
      ],
      "metadata": {
        "id": "NWXX2SQw6JI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = output('../Fruit_Vegetable_Recognition/Dataset/train/cabbage/Image_1.jpg')\n",
        "img"
      ],
      "metadata": {
        "id": "smBHglL-6JF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('FV.h5')"
      ],
      "metadata": {
        "id": "nABipHEm6JDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5lRnwoCL6I-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sIPtu4wg6I7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}